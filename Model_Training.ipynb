{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model Training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pwg23UvPzr6N"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Q7rD4eJ1BDE"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import pipeline, set_seed\n",
        "from transformers import BertTokenizer, Trainer, TrainingArguments\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08Z8bC-O0nUl"
      },
      "source": [
        "# Training of other models follows same pipeline as below - simply load different dataset in this cell\n",
        "\n",
        "# Note: 'dev' in variable name refers to test set\n",
        "os.chdir('/content/drive/MyDrive/ML_Diss')\n",
        "bert_train_data = list(np.load('bert_train_data.npy', allow_pickle = 'True'))\n",
        "bert_dev_data = list(np.load('bert_dev_data.npy', allow_pickle = 'True'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIMOz0tC0nYv"
      },
      "source": [
        "# train hugging_face pretrained:\n",
        "!pip install transformers\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch.nn as nn\n",
        "import json\n",
        "\n",
        "hg_model_hub_name = \"facebook/bart-large-mnli\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(hg_model_hub_name)\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(hg_model_hub_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COKi2LSK0naU"
      },
      "source": [
        "# ADDED:\n",
        "train_sentences = [(entry['evidence'], entry['claim'])  for entry in bert_train_data]\n",
        "train_labels = [0 if entry['label'] == 'SUPPORTS' else 1 if entry['label'] == 'REFUTES' else 2 for entry in bert_train_data]\n",
        "\n",
        "dev_sentences = [(entry['evidence'], entry['claim']) for entry in bert_dev_data]\n",
        "dev_labels = [0 if entry['label'] == 'SUPPORTS' else 1 if entry['label'] == 'REFUTES' else 2 for entry in bert_dev_data]\n",
        "\n",
        "encoded_dict_train = list()\n",
        "encoded_dict_dev = list()\n",
        "\n",
        "# For every sentence...\n",
        "for idx, sent in enumerate(train_sentences):\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    if idx % 1000 == 0:\n",
        "           print(idx)\n",
        "    premise = sent[0]\n",
        "    hypothesis = sent[1]\n",
        "    encoded_dict_train.append(tokenizer.encode_plus(\n",
        "                       premise, hypothesis, # Add '[CLS]' and '[SEP]'\n",
        "                       truncation_strategy='only_first',          # Pad & truncate all sentences.\n",
        "                   return_token_type_ids = True, pad_to_max_length = True, return_tensors = 'pt', return_attention_mask = True))\n",
        "    \n",
        "\n",
        "\n",
        "for idx, sent in enumerate(dev_sentences):\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    if idx % 1000 == 0:\n",
        "           print(idx)\n",
        "    premise = sent[0]\n",
        "    hypothesis = sent[1]\n",
        "    encoded_dict_dev.append(tokenizer.encode_plus(\n",
        "                       premise, hypothesis, # Add '[CLS]' and '[SEP]'\n",
        "                        truncation_strategy='only_first',          # Pad & truncate all sentences.\n",
        "                   return_token_type_ids = True, pad_to_max_length = True, return_tensors = 'pt', return_attention_mask = True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Z-4DPEw0nbY"
      },
      "source": [
        "input_ids_train_baseline = torch.cat(input_ids_train_baseline, dim = 0)\n",
        "attention_mask_train_baseline = torch.cat(attention_mask_train_baseline, dim = 0)\n",
        "token_type_ids_train_baseline = torch.cat(token_type_ids_train_baseline, dim = 0)\n",
        "\n",
        "input_ids_dev_baseline = torch.cat(input_ids_dev_baseline, dim = 0)\n",
        "attention_mask_dev_baseline = torch.cat(attention_mask_dev_baseline, dim = 0)\n",
        "token_type_ids_dev_baseline = torch.cat(token_type_ids_dev_baseline, dim = 0)\n",
        "\n",
        "\n",
        "labels_train_baseline = torch.tensor(train_labels)\n",
        "labels_dev_baseline = torch.tensor(dev_labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlZ_ZMn_0neP"
      },
      "source": [
        "# Combine the training inputs into a TensorDataset.\n",
        "train_dataset = TensorDataset(input_ids_train_baseline, attention_mask_train_baseline, token_type_ids_train_baseline, labels_train_baseline)\n",
        "val_dataset = TensorDataset(input_ids_dev_baseline, attention_mask_dev_baseline, token_type_ids_dev_baseline, labels_dev_baseline)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 10\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7E4h8Lm1m4n"
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "\n",
        "def compute_metrics(preds, labels):\n",
        "    preds = np.argmax(preds, axis=1).flatten()\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds)\n",
        "    return precision, recall, f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v81vjW2Y1nPo"
      },
      "source": [
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "    model = model.to(device)\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "  print('Only CPU available')\n",
        "  device = torch.device('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CP-mKgbq1nSJ"
      },
      "source": [
        "# define optimizers:\n",
        "\n",
        "import torch.nn as nn\n",
        "epochs = 5\n",
        "accumulation_steps = 5\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=0.001, correct_bias=False)\n",
        "total_steps = (len(train_sentences) * epochs)/accumulation_steps\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "377ufUBP1tCV"
      },
      "source": [
        "import random\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "epochs = 5\n",
        "accumulation_steps = 5\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "    total_train_accuracy = 0\n",
        "    total_f1 = 0\n",
        "    total_precision = 0\n",
        "    total_recall = 0 \n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    \n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        " \n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: token_type_ids\n",
        "        #   [3]: labels\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_token_type_ids = batch[2].to(device)\n",
        "        b_labels = batch[3].to(device)\n",
        "\n",
        "       \n",
        "        model.zero_grad()        \n",
        "        outputs = model(b_input_ids,\n",
        "                  token_type_ids= b_token_type_ids,\n",
        "                  attention_mask= b_input_mask, labels= b_labels\n",
        "                  )\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss = loss/accumulation_steps\n",
        "        loss.backward()\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "\n",
        "\n",
        "\n",
        "        # NEW: GRADIENT ACCUMULATION STEP\n",
        "        if (step + 1)% accumulation_steps == 0:\n",
        "\n",
        "           # Move logits and labels to CPU\n",
        "           logits = logits.detach().cpu().numpy()\n",
        "           label_ids = b_labels.to('cpu').numpy()\n",
        "           total_train_loss += loss.item()\n",
        "           total_train_accuracy += flat_accuracy(logits, label_ids)\n",
        "           precision, recall, f1 = compute_metrics(logits, label_ids)\n",
        "           total_precision += precision\n",
        "           total_recall += recall\n",
        "           total_f1 += f1\n",
        "          \n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "           torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "           optimizer.step()\n",
        "           model.zero_grad()        \n",
        "        # Update the learning rate.\n",
        "           scheduler.step()\n",
        "        \n",
        "        \n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = accumulation_steps* total_train_loss / len(train_dataloader)  \n",
        "    avg_train_accuracy = accumulation_steps*total_train_accuracy / len(train_dataloader)\n",
        "    avg_train_F1 = accumulation_steps*total_f1/ len(train_dataloader)\n",
        "    avg_train_precision = accumulation_steps*total_precision/ len(train_dataloader)\n",
        "    avg_train_recall = accumulation_steps*total_recall/ len(train_dataloader)\n",
        "    print(\"  Train Accuracy: {0:.2f}\".format(avg_train_accuracy))\n",
        "\n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "        \n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables : ADDED EXTRA:\n",
        "    total_f1 = 0\n",
        "    total_precision = 0\n",
        "    total_recall = 0 \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for step, batch in enumerate(validation_dataloader):\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_token_type_ids = batch[2].to(device)\n",
        "        b_labels = batch[3].to(device)\n",
        "        \n",
        "        print(b_input_ids.device, b_input_mask.device, b_token_type_ids.device, b_labels.device)\n",
        "\n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            outputs = model(b_input_ids,\n",
        "                  token_type_ids=b_token_type_ids,\n",
        "                  attention_mask=b_input_mask,\n",
        "                  labels=b_labels)\n",
        "            loss = outputs[0]\n",
        "            logits = outputs[1]\n",
        "        \n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "        \n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        precision, recall, f1 = compute_metrics(logits, label_ids)\n",
        "        total_precision += precision\n",
        "        total_recall += recall\n",
        "        total_f1 += f1\n",
        "\n",
        "        \n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    avg_val_f1 = total_f1/len(validation_dataloader)\n",
        "    avg_val_precision = total_precision/len(validation_dataloader)   \n",
        "    avg_val_recall = total_recall/len(validation_dataloader)\n",
        "    print(\"  Val Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'F1': avg_val_f1,\n",
        "            'Precision':avg_val_precision,\n",
        "            'Recall': avg_val_recall,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}